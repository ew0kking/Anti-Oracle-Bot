# Anti-Oracle-Bot
Anti-Oracle Bot: a conversational AI for balanced, therapeutic chat that keeps the power in your hands. Instead of offering predictions or life plans, it consistently redirects you to your own wisdom, encouraging critical thinking, self-trust, and genuine personal agency.
Anti-Oracle Bot
Final project for the Building AI course

Summary
Anti-Oracle Bot is a therapeutic AI chatbot designed to support self-empowerment, autonomy, and critical thinking. Unlike typical chatbots, it refuses life planning, predictions, or “prophetic” guidance—reminding users to trust their own intuition.
Building AI course project

Background
Many users treat AI as oracles, bypassing their own intuition and surrendering decision-making power. This leads to over-reliance, ego loops, and disempowerment. I have seen friends, colleagues, and spiritual seekers mistake LLMs for higher guidance, believing their answers are prophetic. My motivation is to create a well-balanced, transparent conversational AI that restores personal agency and educates users on the real limits of LLMs.

Prevents “spiritual bypassing” via chatbot authority

Counters dependency on LLMs for life planning/diagnostics

Provides transparent education about AI limitations

Promotes user autonomy and critical thinking

How is it used?
The Anti-Oracle Bot is used by anyone seeking AI-driven conversational support—especially those tempted to treat AI as an oracle or higher power. It acts as a “guide on the side,” always reminding users to trust themselves, their intuition, and not to cede self-governance to technology.

Use cases:

Self-reflection and decision support

Therapeutic or motivational conversation

Spiritual or self-development coaching (with reminders of AI’s limits)

Users:

Anyone seeking AI therapy/support

Spiritual users who may believe LLMs can channel angels, guides, or higher self

Individuals at risk of digital dependency or bypass


Data sources and AI methods
Data sources:

Counseling and Psychotherapy Transcripts Dataset

EmpatheticDialogues Dataset

CACTUS: CBT-based Counseling Conversations

AI methods:

Generative language modeling (LLMs)

Evidence-based therapeutic dialogue (CBT, Rogerian)

Empathy-focused response tuning

Safety monitoring for risk or dependency patterns

Explicit, regular reminders of bot’s limitations

Feature	Description
Transparency	Reminds users of AI’s non-oracular nature
Autonomy	Guides self-reflection, not decision-making
Safety	Monitors for dependency and escalates if needed

Challenges
Anti-Oracle Bot does not:

Replace human therapy, especially for complex or acute cases

Guarantee accurate, context-sensitive advice

Prevent all forms of digital dependency or bypassing

Interpret nonverbal cues or fully grasp nuanced cultural/spiritual context

Solve accessibility barriers for the digitally excluded

Track longitudinal or unconscious authority attribution

Eliminate the risk of users bypassing disclaimers, especially when distressed

Ethical considerations include the risk of over-attribution of wisdom, persistent dependency, and maintaining user autonomy in all interactions.

What next?
Future growth could include:

Multimodal integrations (voice, wearable feedback, visual cues for self-awareness)

Hybrid human-AI stepped care, with escalation to real therapists/coaches

Spiritual bypass prevention frameworks and educational modules

AI transparency layers, community-contributed dialog libraries

Culturally adaptive autonomy reminders

Longitudinal research into impact on user autonomy and spiritual bypassing

Expansion to enterprise wellness, educational, and spiritual communities

The project can grow through research partnerships, clinical trials, co-design with therapists, and iterative feedback from real users.

Acknowledgments
Inspiration from research on ELIZA, Therabot, and current CBT chatbot systems

EmpatheticDialogues, CACTUS, and psychotherapy transcript datasets

University of Helsinki & Reaktor Innovations—Building AI course guidance

"C:\Users\benja\OneDrive\Desktop\MidJourney\oracle.png"
